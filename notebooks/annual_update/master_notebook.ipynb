{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annual updating of AusEFlux <img align=\"right\" src=\"https://github.com/cbur24/AusEFlux/blob/master/results/banner_picture.png?raw=True\" width=\"40%\">\n",
    "\n",
    "Text describing how to use this notebook goes here\n",
    "\n",
    "Basically, just run the notebook. There are 4 steps to run. \n",
    "\n",
    "Pay attention to the `Analysis Parameters` sections and ensure paths etc. are correct\n",
    "\n",
    "***\n",
    "**Ideal compute environment:**\n",
    "\n",
    "Assuming 5-km resolution\n",
    "\n",
    "- NCI's 'normal' queue\n",
    "- X-large (24 cores, 95GiB)\n",
    "- Python 3.10.0\n",
    "- Python venv: `/g/data/os22/chad_tmp/AusEFlux/env/py310`\n",
    "- Folders: `gdata/os22+gdata/ub8+gdata/xc0+gdata/gh70`\n",
    "***\n",
    "> **Expected completion time to run all steps: ~3 hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries and set up Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/os22/chad_tmp/AusEFlux/src/')\n",
    "from _utils import start_local_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = start_local_dask(mem_safety_margin='2Gb')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Spatiotemporal harmonisation of input datasets\n",
    "\n",
    "Most datasets are originally from here: https://dapds00.nci.org.au/thredds/catalog/ub8/au/catalog.html\n",
    "\n",
    "**Expected completion time ~2hrs**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `base`: Path to where most of the data is stored\n",
    "* `results`: Path to store interim datasets after they have undergone harmonisatin\n",
    "* `year_start`: The first year in the series to predict. If predicting for a single year, make `year_start` and `year_end` the same.\n",
    "* `year_end`: The last year in the series to predict. If predicting for a single year, make `year_start` and `year_end` the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/g/data/ub8/au/'\n",
    "results='/g/data/os22/chad_tmp/AusEFlux/data/interim/'\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run harmonisation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _harmonisation import spatiotemporal_harmonisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spatiotemporal_harmonisation(year=year,\n",
    "                             year_end=year,\n",
    "                             base_path=base,\n",
    "                             results_path=results,\n",
    "                             verbose=True\n",
    "                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create feature datasets\n",
    "\n",
    "Combine results of the spatiotemporal harmonisation into temporally stacked netcdf files, and create new features/variables based on the climate (e.g. anomalies) and remote sesning (e.g veg fractions) datasets. \n",
    "\n",
    "**Expected completion time 5 mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `base`: Path to where the harmonised datasets output from Step 1 are stored. \n",
    "* `results`: Path to store temporally stacked netcdf files i.e. where the outputs of Step 2 will be stored\n",
    "* `exclude`: Variables to exclude from combining. i.e. Some of the variables in `/interim` output in Step 1 are not needed hereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = '/g/data/os22/chad_tmp/AusEFlux/data/interim/'\n",
    "results='/g/data/os22/chad_tmp/AusEFlux/data/5km/'\n",
    "exclude = ['.ipynb_checkpoints', 'kTavg', 'Tmax', 'Tmin', 'EVI']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _feature_datasets import create_feature_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_feature_datasets(base=base,\n",
    "                       results_path=results,\n",
    "                       exclude=exclude,\n",
    "                       verbose=True\n",
    "                       )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Predict ensemble\n",
    "\n",
    "Using the ensemble of models, we will generate an ensemble of gridded predictions.\n",
    "\n",
    "**Expected completion time 30 mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `base`: Path to where the harmonised datasets output from Step 1 are stored. \n",
    "* `results_path`: Path to store temporally stacked netcdf files i.e. where the outputs of Step 2 will be stored\n",
    "* `year_start`: The first year in the series to predict. If predicting for a single year, make `year_start` and `year_end` the same.\n",
    "* `year_end`: The last year in the series to predict. If predicting for a single year, make `year_start` and `year_end` the same.\n",
    "* `models_folder`: where are the models stored?\n",
    "* `features_list`: Where are the list of features used by the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = 'GPP'\n",
    "base = '/g/data/os22/chad_tmp/AusEFlux/'\n",
    "year_start, year_end='2023','2023'\n",
    "results_path = f'{base}results/predictions/ensemble/annual_update/{t1}/{model_var}/'\n",
    "models_folder = f'{base}results/models/ensemble/{model_var}/'\n",
    "features_list = f'{base}results/variables.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Step 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _ensemble_prediction import predict_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_ensemble(\n",
    "   base=base,\n",
    "   model_var=model_var,\n",
    "   models_folder=models_folder,\n",
    "   features_list=features_list\n",
    "   year_start=year_start,\n",
    "   year_end=year_end\n",
    "   compute_early=True,\n",
    "   verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Combine ensembles\n",
    "\n",
    "Ran an ensemble of predictions, now we need to compute the ensemble median and the uncertainty range.\n",
    "\n",
    "This step will also output production ready datasets with appropriate metadata\n",
    "\n",
    "**Expected completion time 10 mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `base`: Path to where the harmonised datasets output from Step 1 are stored. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_var = 'GPP'\n",
    "base = '/g/data/os22/chad_tmp/AusEFlux/'\n",
    "year = '2023'\n",
    "predictions_folder= f'{base}results/predictions/ensemble/annual_update/{year}/{model_var}/'\n",
    "\n",
    "#metadata for export\n",
    "full_name = 'Gross Primary Productivity'\n",
    "version = 'v1.2'\n",
    "units = 'gC/m2/month'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
