{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Annual updating of AusEFlux <img align=\"right\" src=\"https://github.com/cbur24/AusEFlux/blob/master/banner_picture.png?raw=True\" width=\"40%\">\n",
    "\n",
    "This notebook executes a workflow for annual updating of AusEFlux terrestrial carbon and water fluxes. It contains four main steps, instructions are provided in the subsections below. Pay close attention to the `Analysis Parameters` sections and ensure paths etc. are correct.\n",
    "\n",
    "***\n",
    "**Ideal compute environment:**\n",
    "\n",
    "Assuming 500m resolution\n",
    "\n",
    "- NCI's 'hugemem' queue\n",
    "- X-large (24 cores, 765GiB)\n",
    "- Python 3.10.0\n",
    "- Python venv: `/g/data/xc0/project/AusEFlux/env/py310`\n",
    "- Storage Folders: `gdata/ub8+gdata/xc0+gdata/gh70`\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up Dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import sys\n",
    "sys.path.append('/g/data/xc0/project/AusEFlux/src/')\n",
    "from _utils import start_local_dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "client = start_local_dask(mem_safety_margin='2Gb')\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up project directory structure\n",
    "\n",
    "This workflow assumes a specific file/folder structure, here we create that folder structure to support the rest of the process.\n",
    "\n",
    "Below, enter the `root directory location` where project results and data are stored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root='/g/data/xc0/project/AusEFlux'\n",
    "target_grid = '500m'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _utils import create_project_directories\n",
    "create_project_directories(root_dir=root, target_grid=target_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Spatiotemporal harmonisation of input datasets\n",
    "\n",
    "Most datasets are originally from here: https://thredds.nci.org.au/thredds/catalog/ub8/au/catalog.html\n",
    "\n",
    "Dataset from this process are output as annual layers in `data/interim`\n",
    "\n",
    "**Expected completion time at 500m ~3 hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `results`: Path to store interim datasets after they have undergone harmonisatin\n",
    "* `year`: The year of data we are processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_grid = '500m'\n",
    "results=f'/g/data/xc0/project/AusEFlux/data/interim_{target_grid}/'\n",
    "year = 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run step 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _harmonisation import spatiotemporal_harmonisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "spatiotemporal_harmonisation(\n",
    "    year_start=year,\n",
    "    year_end=year,\n",
    "    target_grid=target_grid,\n",
    "    results_path=results,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create feature datasets\n",
    "\n",
    "Combine results of the spatiotemporal harmonisation into temporally stacked netcdf files, and create new features/variables based on the climate (e.g. anomalies) and remote sensing (e.g vegetation fractions) datasets. \n",
    "\n",
    "**Expected completion time at 500m resolution is ~6 hours**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `base`: Path to where the harmonised datasets output from Step 1 are stored. \n",
    "* `results`: Path to store temporally stacked netcdf files i.e. where the outputs of Step 2 will be stored\n",
    "* `exclude`: Variables to exclude from combining. i.e. Some of the variables in `/interim` output in Step 1 are not needed hereafter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#results are stored in different directory due to storage issues\n",
    "target_grid = '500m'\n",
    "base = f'/g/data/xc0/project/AusEFlux/data/interim_{target_grid}/'\n",
    "results=f'/g/data/xc0/project/AusEFlux/data/{target_grid}/'\n",
    "exclude = ['.ipynb_checkpoints', 'kTavg', 'Tmax', 'Tmin']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _feature_datasets import create_feature_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "create_feature_datasets(\n",
    "    base=base,\n",
    "    results_path=results,\n",
    "    exclude=exclude,\n",
    "    target_grid=target_grid,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Predict ensemble\n",
    "\n",
    "Using the ensemble of models, we will generate an ensemble of gridded predictions. The code below will loop through the carbon and water fluxes.\n",
    "\n",
    "**Expected completion time X mins/flux, so approximately X hours total if running all four fluxes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "* `fluxes`: The list of fluxes to loop through and predict. Most times this shouldn't need to change.\n",
    "* `base`: Path to the root directory\n",
    "* `year_start`: The first year in the series to predict. If predicting for a single year, make _year_start_ and _year_end_ the same.\n",
    "* `year_end`: The last year in the series to predict. If predicting for a single year, make _year_start_ and _year_end_ the same.\n",
    "* `features_list`: Where are the list of features used by the model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = ['GPP','NEE','ER','ET']\n",
    "base = '/g/data/xc0/project/AusEFlux/'\n",
    "year_start, year_end=2023, 2023\n",
    "target_grid='500m'\n",
    "features_list = f'{base}results/variables.txt'\n",
    "prediction_data=results=f'/g/data/xc0/project/AusEFlux/data/{target_grid}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Step 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _ensemble_prediction import predict_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in fluxes:\n",
    "    # set up paths\n",
    "    results_path = f'{base}results/predictions/annual_update/{year_start}/{f}/'\n",
    "    models_folder = f'{base}results/models/ensemble/{f}/'\n",
    "\n",
    "    #predict ensemble\n",
    "    predict_ensemble(\n",
    "       base=base,\n",
    "       prediction_data=prediction_data,\n",
    "       model_var=model_var,\n",
    "       models_folder=models_folder,\n",
    "       features_list=features_list,\n",
    "       results_path=results_path,\n",
    "       year_start=year_start,\n",
    "       year_end=year_end,\n",
    "       target_grid=target_grid,\n",
    "       compute_early=False,\n",
    "       verbose=True\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Combine ensembles\n",
    "\n",
    "Ran an ensemble of predictions, now we need to compute the ensemble median and the uncertainty range.\n",
    "\n",
    "This step will also output production ready datasets with appropriate metadata, including annual summaries.  All datasets will be export to /g/data/ub8/au/AusEFlux/[version]/\n",
    "\n",
    "The code below will loop through the carbon and water fluxes.\n",
    "\n",
    "**Expected completion time X mins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis Parameters\n",
    "\n",
    "* `fluxes`: A dictionary linking the fluxes to be modelled (e.g 'GPP', 'NEE' etc.) with their full names (e.g. 'Gross Primary Productivity'). This dictionary is used to loop through the fluxes for combining the ensembles, and the full name is used for metadata on the exported netcdf.\n",
    "* `results_path`: Where are we exporting the final results? Usually this will be 'ub8/au/AusEFlux/'\n",
    "* `year_start`: The first year in the series. If running for a single year, make _year_start_ and _year_end_ the same.\n",
    "* `year_end`: The last year in the series. If running for a single year, make _year_start_ and _year_end_ the same.\n",
    "* `quantiles`: What quantiles are we using to determine the middle value and uncertainty range? The default is 0.25 and 0.75 for the uncertainty envelope, and 0.5 (median) for the middle estimate.\n",
    "* `version`: What version of the dataset is this?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fluxes = {\n",
    "    'GPP':'Gross Primary Productivity',\n",
    "    'NEE':'Net Ecosystem Exchange',\n",
    "    'ER':'Ecosystem Respiration',\n",
    "    'ET':'Evapotranspiration'\n",
    "         }\n",
    "\n",
    "predictions_path = '/g/data/xc0/project/AusEFlux/results/predictions/annual_update/'\n",
    "year_start, year_end=2024,2024\n",
    "quantiles=[0.25,0.5,0.75] # interquartile range\n",
    "version = 'v2.0'\n",
    "results_path = f'/g/data/ub8/au/AusEFlux/{version}/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run step 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _combine_ensemble import combine_ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for f,n in fluxes.items():\n",
    "\n",
    "    # paths\n",
    "    # predictions_folder= f'{base}results/predictions/ensemble/annual_update/{year_start}/{f}/'\n",
    "    predictions_folder= f'{predictions_path}{year_start}/{f}/'\n",
    "\n",
    "    # metadata for netcdf attributes\n",
    "    if f =='ET':\n",
    "        units = 'mm/month'\n",
    "    else:\n",
    "        units = 'gC/m\\N{SUPERSCRIPT TWO}/month'\n",
    "    \n",
    "    description = f'AusEFlux {n} is created by empirically upscaling the OzFlux eddy covariance network using machine learning methods coupled with climate and remote sensing datasets. The estimates provided within this dataset were extracted from an ensemble of predictions and represent the median and uncertainty range.'\n",
    "\n",
    "    # Create attributes dictionary\n",
    "    attrs_dict={}\n",
    "    attrs_dict['nodata'] = np.nan\n",
    "    attrs_dict['crs'] = 'EPSG:4326'\n",
    "    attrs_dict['short_name'] = f\n",
    "    attrs_dict['long_name'] = n\n",
    "    attrs_dict['units'] = units\n",
    "    attrs_dict['version'] = version\n",
    "    attrs_dict['description'] = description\n",
    "\n",
    "    #combine ensembles and save netcdf\n",
    "    combine_ensemble(\n",
    "        model_var=f,\n",
    "        results_path=results_path,\n",
    "        predictions_folder=predictions_folder,\n",
    "        year_start=year_start,\n",
    "        year_end=year_end,\n",
    "        attrs=attrs_dict,\n",
    "        quantiles=quantiles,\n",
    "        verbose=True\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## You're done!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Last Run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "print(date.today())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
